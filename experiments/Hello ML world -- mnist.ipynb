{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple notebook to demonstrate that the hello world is properly configured\n",
    "\n",
    "Goals:\n",
    "- Train a simple neural network on the MNIST dataset. \n",
    "- Log the training progress to Weight and Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from inria.helloworld.models import HelloWorldMlp\n",
    "from inria.helloworld.datamodules import MnistDataModule\n",
    "from inria.helloworld.trainer_args import TrainerArgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check if we have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"GPU available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "MODELS_DIR = Path.cwd().parent / \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT_DIR = MODELS_DIR / \"checkpoints\"\n",
    "BEST_MODEL_DIR = MODELS_DIR / \"best_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MnistDataModule(DATA_DIR)\n",
    "mnist.prepare_data()\n",
    "mnist.setup()\n",
    "\n",
    "# grab samples to log predictions on\n",
    "samples = next(iter(mnist.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use a particular wandb entity\n",
    "# os.environ['WANDB_ENTITY'] = \"other-entity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"inria-helloworld-mnist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have followed the instructions on `README.md`, wandb should be transparent to set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are resuming training we want to check what runs are available in WandB, so we can resume it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for run in wandb.Api().runs(path=os.environ[\"WANDB_ENTITY\"] + \"/\" + WANDB_PROJECT):\n",
    "        when = (\n",
    "            datetime.fromtimestamp(run.summary[\"_timestamp\"]).strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "            if \"_timestamp\" in run.summary\n",
    "            else \"--\"\n",
    "        )\n",
    "        print(f\"Run id: {run.id} '{run.name}' {when} ({run.state}): {run.url}\")\n",
    "except ValueError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_RUN_ID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUME_RUN_ID = '2em89whs'  # write here the run that you want to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(dir=MODELS_DIR, project=WANDB_PROJECT, resume=\"allow\", id=RESUME_RUN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb.run.resumed:\n",
    "    print(\"Resumming training from.\")\n",
    "    model = torch.load(wandb.restore(\"model.ckpt\").name)  # setup model\n",
    "else:\n",
    "    model = HelloWorldMlp(in_dims=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=BEST_MODEL_DIR, save_top_k=1, verbose=False, monitor=\"valid/loss_epoch\", mode=\"min\"\n",
    ")\n",
    "resume_checkpoint_callback = ModelCheckpoint(dirpath=MODEL_CHECKPOINT_DIR, save_last=True, save_on_train_epoch_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"valid/loss_epoch\", min_delta=0.01, patience=3, verbose=False, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(save_dir=MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainerArgs(\n",
    "    max_epochs=1000,\n",
    "    log_every_n_steps=10,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[best_models_checkpoint_callback, resume_checkpoint_callback, early_stop_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(**args.to_dict())  # passing training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb.run.resumed and (MODEL_CHECKPOINT_DIR / \"last.ckpt\").exists():\n",
    "    print(\"Resuming training from last checkpoint.\")\n",
    "    trainer.fit(ckpt_path=str(MODEL_CHECKPOINT_DIR / \"last.ckpt\"))\n",
    "else:\n",
    "    print(\"Starting training from scratch.\")\n",
    "    trainer.fit(model, mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on a test set\n",
    "trainer.test(datamodule=mnist, ckpt_path=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "194aae175b9538ea009115c4503dfd4aa249c5e5fc93004dbb58bc2046dc0cc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
